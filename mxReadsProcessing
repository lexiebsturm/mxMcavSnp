#####Note Libraries were prepared twice and sequenced spearately, the first run JA20232 yielded few reads and the second run JA20302 was much better (see separate directories for raw reads), quality control was conducted on both sets of samples and angsd was run on all the files to ensure that run did not have a major effect (see mergedRun). Samples that were sequenced in both runs still clustered tightly together suggesting that run did not have much of an effect on sequencing. We then merged all the files together, concatenating any samples that were sequenced across both runns and collating the rest to have the most complete dataset possible

#Unzip all raw fastq.gz files
srun gunzip *.gz
srun perl countreads_raw.pl #ensure the file name in the fastq files

mkdir concatRun
cd concatRun

mkdir catHighQuality
cd catHighQuality
srun cp ~/2bRAD/mexico/JA20302/highQualityReads/*.trim .
srun cp ~/2bRAD/mexico/JA20232/highQualityReads/*.trim .

##Open concatenatedFiles text file to see how files were concatenated and renamed
##There should be 106 files in total

#Count reads following trimming and filtering
srun perl countreads_raw.pl #ensure the file name in the trim files

################################################################################
mkdir sams
srun cp ./catHighQuality/*.trim ./sams

#Ensure that the concatenated MCAV and algal symbiont transcriptomes are in this directory along with the associated genome index files

cd sams

# mapping with --local option, enables clipping of mismatching ends (guards against deletions near ends of RAD tags)
#First align all high-quality reads to the zoox genomes

mkdir unaligned
mkdir zoox

2bRAD_bowtie2_launcher_ryan.py -f trim -g ~/genomes/symbiontGenomes/singleChromo/concatZooxGenomes.fasta.gz --split -a zoox -u unal --undir ./unaligned --aldir ./zoox -n maps --launcher -e asturm2017@fau.edu

#What this will do is align all your high-quality reads to a concatenated zoox genome. Then will output 3 file types.
#In the working directory will output SAMs files with only reads that aligned to the Zoox genomes
#In the unaligned directory you will have fastq files of reads that did not align to the zoox genomes, copy these over to the mcavSams directory and align to the MCAV genome

cd zoox
mkdir dualAligned
mkdir zooxOnly

2bRAD_bowtie2_launcher_ryan.py -f trim.zoox -g ~/genomes/Mcav_genome/Mcavernosa_July2018.fasta --split -a dual -u zooxOnly --undir ./zooxOnly --aldir ./dualAligned -n maps --launcher -e asturm2017@fau.edu
sbatch maps.slurm

#In the zoox directory you will have fastq files that aligned to the zoox genomes, realign back to the MCAV genome and again split these reads up into aligned and unaligned. In this case only used the unaligned reads because then you will get rid of any potential dual-aligned reads to both MCAV and algal symbiont.

cd zooxOnly
2bRAD_bowtie2_launcher_ryan.py -f trim.zoox.zooxOnly -g ~/genomes/symbiontGenomes/singleChromo/concatZooxGenomes.fasta.gz -n zooxOnlyMaps --launcher -e asturm2017@fau.edu
sbatch zooxOnlyMaps.slurm

#This makes zooxOnly Sams
################################################################################
mkdir mcavSams
srun cp ./sams/unaligned/*.unal ./mcavSams

2bRAD_bowtie2_launcher_ryan.py -f unal -g ~/genomes/Mcav_genome/Mcavernosa_July2018.fasta -n mcavMaps --launcher -e asturm2017@fau.edu


#These sam files should now only have MCAV reads

################################################################################
mkdir zooxSams
mv ~/2bRAD/mexico/concatRun/sams/zoox/zooxOnly/*.sam ~/2bRAD/mexico/concatRun/zooxSams

################################################################################
mkdir zooxBams
srun cp ~/2bRAD/mexico/concatRun/zooxSams/*sam ./zooxBams

#Compressing, sorting and indexing the SAM files, so they become BAM files:
>s2b
for file in *.sam; do
echo "samtools sort -O bam -o ${file/.sam/}.bam $file && samtools index ${file/.sam/}.bam">>s2b;
done

launcher_creator.py -j s2b -n s2b -t 6:00:00 -e asturm2017@fau.edu -q shortq7
sbatch s2b.slurm

ls *bam >zooxBams
################################################################################
mkdir mcavBams
srun cp ./mcavSams/*.sam ./mcavBams

#Compressing, sorting and indexing the SAM files, so they become BAM files:
>s2b
for file in *.sam; do
echo "samtools sort -O bam -o ${file/.sam/}.bam $file && samtools index ${file/.sam/}.bam">>s2b;
done

launcher_creator.py -j s2b -n s2b -t 6:00:00 -e asturm2017@fau.edu -q shortq7
sbatch s2b.slurm

ls *bam >bams

################################################################################
srun cp ./mcavBams/*bam* ./mcavANGSDClones/

# angsd settings:
# -minMapQ 20 : only highly unique mappings (prob of erroneous mapping = 1%)
# -baq 1 : realign around indels (not terribly relevant for 2bRAD reads mapped with --local option)
# -maxDepth : highest total depth (sum over all samples) to assess; set to 10x number of samples

FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -maxDepth 1060"
TODO="-doQsDist 1 -doDepth 1 -doCounts 1 -dumpCounts 2"

srun angsd -b bamsClones -GL 1 $FILTERS $TODO -P 1 -out ddClones

# summarizing results (using modified script by Matteo Fumagalli)

echo '#!/bin/bash' > RQC.sh
echo 'srun Rscript ~/bin/plotQC.R ddClones > qranks' >> RQC.sh
sbatch -e RQC.err -o RQC.out --mem=64000m RQC.sh

# proportion of sites covered at >5x:

cat qranks

# scp dd.pdf to laptop to look at distribution of base quality scores, fraction of sites in each sample passing coverage thresholds, and fraction of sites passing genotyping rates cutoffs. Use these to guide choices of -minQ,  -minIndDepth and -minInd filters in subsequent ANGSD runs

##ANGSD WITH NEW FILTERS W CLONES

# Note: PCA and Admixture are not supposed to be run on data that contain clones or genotyping replicates. For PCA, these can be removed without rerunning ANGSD from the IBS distance matrix; but for ngsAdmix ANGSD must be rerun.

# Generating genotype likelihoods from highly confident (non-sequencing-error) SNPs
# set minInd to 75-80% of your total number of bams
# if you expect very highly differentiated populations with nearly fixed alternative alleles, remove '-hwe_pval 1e-5' form FILTERS
# -doGeno 8 : genotype likelihood format setting for ngsLD; if you want to run PCA, use -doGeno 32 (but I recommend using ibsMat for all ordination work)

FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 80 -snp_pval 1e-5 -minMaf 0.05"

TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doBcf 1 -doPost 1 -doGlf 2"

# Starting angsd with -P the number of parallel processes. Funny but in many cases angsd runs faster on -P 1

srun angsd -b bamsClones -GL 1 $FILTERS $TODO -P 1 -out mxMcavClones

# how many SNPs?
NSITES=`zcat mxMcavClones.mafs.gz | wc -l`
echo $NSITES

#scp the ibs matrix to identify clones

################################################################################
mkdir mcavBamsNoClones
srun cp ./mcavBams/*bam* ./mcavBamsNoClones

##Remove technical replicates and any natural clones, picked sample with the highest coverage to retain
#You should have 97 files
################################################################################
mkdir zooxBamsNoClones
srun cp ./zooxBams/*bam* ./zooxBamsNoClones

##Remove technical replicates and any natural clones, picked sample with the highest coverage to retain
#You should have 97 files

FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 73 -snp_pval 1e-5 -minMaf 0.05"

TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doBcf 1 -doPost 1 -doGlf 2"

srun angsd -b zooxBamsNoClones -GL 1 $FILTERS $TODO -P 1 -out mxZooxNoClones

# how many SNPs?
NSITES=`zcat mxZooxNoClones.mafs.gz | wc -l`
echo $NSITES

for i in *.bam; do
    echo $i >> output
    samtools idxstats $i | cut -f 1,3 >> zooxGenomeAlignmentRate
done
################################################################################
mkdir mcavAngsdNoClones
srun cp ./mcavBamsNoClones/*bam* ./mcavAngsdNoClones

# set minInd to 75% of your total number of bams

FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 73 -snp_pval 1e-5 -minMaf 0.05"

TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doBcf 1 -doPost 1 -doGlf 2"

srun angsd -b bamsNoClones -GL 1 $FILTERS $TODO -P 1 -out mxMcavNoClones

# how many SNPs?
NSITES=`zcat mxMcavNoClones.mafs.gz | wc -l`
echo $NSITES

mkdir ngsAdmix
cp mxMcavNoClones.beagle.gz ./ngsAdmix
cd ngsAdmix

# NgsAdmix for K from 2 to 11 : do not run if the dataset contains clones or genotyping replicates!
#for K in `seq 2 11` ;
#do
#NGSadmix -likes mxMcavNoClones.beagle.gz -K $K -P 10 -o mxMcavNoClones_k${K};
#done

## Next, take the likelihood value from each run of NGSadmix and put them into a file that can be used with Clumpak to calculate the most likely K using the methods of Evanno et al. (2005).
>ngsAdmix
for R in {1..10}; do
for K in {1..11}; do
echo "NGSadmix -likes mxMcavNoClones.beagle.gz -K $K -P 10 -o mxMcavNoClones_k${K}_run$R" >> ngsAdmix;
done;
done

launcher_creator.py -j ngsAdmix -n ngsAdmix -q shortq7 -N 3 -t 06:00:00

sbatch ngsAdmix.slurm

mkdir structureSelector

srun cp *.qopt ./structureSelector
cd structureSelector
rename .qopt .Q *.qopt
#Copy these and download as zipped directory

> logfile

for log in *.log; do
grep -Po 'like=\K[^ ]+' $log >> logfile;
done

#format for CLUMPAK in R
R
# you are now using R in the terminal
logs <- as.data.frame(read.table("logfile"))
logs$K <- c(rep("10", 10), rep("11", 10), rep("1", 10), rep("2", 10), rep("3", 10), rep("4", 10), rep("5", 10), rep("6", 10), rep("7", 10), rep("8", 10), rep("9", 10))
write.table(logs[, c(2, 1)], "logfile_formatted", row.names = F, col.names = F, quote = F)      
quit()

###relatedness

FILTERS="-uniqueOnly 1 -remove_bads 1 -minMapQ 20 -minQ 25 -dosnpstat 1 -doHWE 1 -hwe_pval 1e-5 -sb_pval 1e-5 -hetbias_pval 1e-5 -skipTriallelic 1 -minInd 73 -snp_pval 1e-5 -minMaf 0.05"

TODO="-doMajorMinor 1 -doMaf 1 -doCounts 1 -makeMatrix 1 -doIBS 1 -doCov 1 -doGeno 8 -doBcf 1 -doPost 1 -doGlf 3"

srun angsd -b bamsNoClones -GL 1 $FILTERS $TODO -P 1 -out mxMcavRelate

zcat mxMcavRelate.mafs.gz | cut -f5 |sed 1d >freq
NIND=`cat bamsNoClones | wc -l`
srun ngsRelate -f freq -g mxMcavRelate.glf.gz -n $NIND -z bamsNoClones >relatedness

#Heterozygosity on variant sites Only
srun --mem=100GB Rscript ~/bin/heterozygosity_beagle.R mxMcavNoClones.beagle.gz
#Prints individual heterozygosity
################################################################################
mkdir bayescan
cd bayescan
srun cp ../macvANGSDNoClones/mxMcavNoClones.vcf.gz . #Note do not use the renamed version, pgdspider has a tough time parsing the samples into pops when you do
srun gunzip mxMcavNoClones.vcf.gz

#scp bspops to koko

echo "############
# VCF Parser questions
PARSER_FORMAT=VCF
# Do you want to include a file with population definitions?
VCF_PARSER_POP_QUESTION=true
# Only input following regions (refSeqName:start:end, multiple regions: whitespace separated):
VCF_PARSER_REGION_QUESTION=
# What is the ploidy of the data?
VCF_PARSER_PLOIDY_QUESTION=DIPLOID
# Only output following individuals (ind1, ind2, ind4, ...):
VCF_PARSER_IND_QUESTION=
# Output genotypes as missing if the read depth of a position for the sample is below:
VCF_PARSER_READ_QUESTION=
# Take most likely genotype if "PL" or "GL" is given in the genotype field?
VCF_PARSER_PL_QUESTION=true
# Do you want to exclude loci with only missing data?
VCF_PARSER_EXC_MISSING_LOCI_QUESTION=false
# Select population definition file:
VCF_PARSER_POP_FILE_QUESTION=./bspops
# Only output SNPs with a phred-scaled quality of at least:
VCF_PARSER_QUAL_QUESTION=
# Do you want to include non-polymorphic SNPs?
VCF_PARSER_MONOMORPHIC_QUESTION=false
# Output genotypes as missing if the phred-scale genotype quality is below:
VCF_PARSER_GTQUAL_QUESTION=
# GESTE / BayeScan Writer questions
WRITER_FORMAT=GESTE_BAYE_SCAN
# Specify which data type should be included in the GESTE / BayeScan file  (GESTE / BayeScan can only analyze one data type per file):
GESTE_BAYE_SCAN_WRITER_DATA_TYPE_QUESTION=SNP
############" >vcf2bayescan.spid

srun java -Xmx1024m -Xms512m -jar ~/bin/PGDSpider_2.0.7.1/PGDSpider2-cli.jar -inputfile mxMcavNoClones.vcf -outputfile mxMcav.bayescan -spid vcf2bayescan.spid

# launching bayescan (this might take 12-24 hours)
srun bayescan mxMcav.bayescan -threads=20

removeBayescanOutliers.pl bayescan=mxMcav.baye_fst.txt vcf=mxMcavNoClones.vcf FDR=0.1 mode=extract > mxVcfOutliers.vcf

srun sed 's/^##fileformat=VCFv4.2(angsd version)/##fileformat=VCFv4.2/' mxVcfOutliers.vcf > mx1VcfOutliers.vcf

removeBayescanOutliers.pl bayescan=mxMcav.baye_fst.txt vcf=mxMcavNoClones.vcf FDR=0.1 mode=delete > mxVcfNeutral.vcf

##Bayescenv
scp asturm2017@koko-login.hpc.fau.edu:/mnt/beegfs/home/asturm2017/2bRAD/mexico/concatRun/bayescan/mxMcav.bayescan /Users/student/bin/bayescenv-1.1/bin/mac64

cd /Users/student/bin/bayescenv-1.1/bin/mac64

nano mxDepth
#10 15 25 35 10 15 25 35

./bayescenv mxMcav.bayescan -env mxDepth
################################################################################
################################################################################

#Calculating population parameters no filter on excess heterozygosity
# estimating site frequency likelihoods for each population, also saving allele frequencies (for genome scan)

mkdir angsdPopStats

srun cp ./mcavBamsNoClones/*bam* ./angsdPopStats #copy over all the bam files (clones removed) and the bam lists for each pop. Pop definitions are below

FILTERS="-uniqueOnly 1 -remove_bads 1  -skipTriallelic 1 -minMapQ 20 -minQ 25 -doHWE 1 -sb_pval 1e-5 -hetbias_pval 1e-5 -minInd 73" #Note there are no MAF or snp filters so as not to affect allelic frequencies that may mess with heterozygosity calcs

TODO="-doMajorMinor 1 -doMaf 1 -dosnpstat 1 -doPost 2 -doGeno 11 -doGlf 2"

srun angsd -b bamsNoClones -GL 1 $FILTERS $TODO -P 1 -out mxMcavNoSNPFilter

NSITES=`zcat mxMcavNoSNPFilter.mafs.gz | wc -l`
echo $NSITES

srun --mem=100GB Rscript ~/bin/heterozygosity_beagle.R mxMcavNoSNPFilter.beagle.gz
#Prints individual heterozygosity

echo '#!/bin/bash' > RHet.sh
echo 'Rscript ~/bin/heterozygosity_beagle.R mxMcavNoSNPFilter.beagle.gz' >> RHet.sh
sbatch -e RHet.e%j -o RHet.o%j --mem=200GB --mail-user asturm2017@fau.edu --mail-type=ALL RHet.sh
